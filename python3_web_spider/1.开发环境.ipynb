{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需要安装的配置\n",
    "\n",
    "配置环境没有全部装上去，感觉自己要学习的还有很多，加油吧\n",
    "\n",
    "\n",
    "| 种类 | 软件和包 | 方式 |\n",
    "| ------ | ------ | --:-- |\n",
    "| Python3 | anaconda✅|  |\n",
    "|         | pycharm✅ |  |\n",
    "| 请求库 | requests✅ |  |\n",
    "|| Selenium✅ | |\n",
    "|| ChromeDriver✅ ||\n",
    "|| GeckoDriver ||\n",
    "|| PhantomJS✅ ||\n",
    "|| aiohttp✅ ||\n",
    "| 解析库 | lxml✅ |  |\n",
    "|| BeautifulSoup✅ ||\n",
    "|| pyquery✅ ||\n",
    "|| tesserocr✅ | *这个库是用来识别图片验证码的 |\n",
    "||| 1. brew install imagemagick \n",
    "|||2.brew install tesseract --with-all-languages \n",
    "|||3.pip install tesserocr pillow|\n",
    "| 数据库 | Mysql✅ |  |\n",
    "|| mongodb✅ ||\n",
    "|| Redis✅ ||\n",
    "| 储存库 | pymysql✅ |  |\n",
    "|| pymongo✅ ||\n",
    "|| redis-py✅ |  |\n",
    "|| redis-dump✅ | *要先装ruby✅ |\n",
    "||||\n",
    "| Web库 | flask✅ |  |\n",
    "|| Tornado✅||\n",
    "| App爬取相关库 | Charles | *收费软件以后再说 |\n",
    "|| mitmproxy & mitmdump & mitmweb✅ | pip3 install mitmproxy |\n",
    "|| Appium✅ ||\n",
    "| 爬虫框架 | pyspider❓ |  |\n",
    "|| scrapy✅ ||\n",
    "|| scrapy-splash✅ | Scrapy 中支持 JavaScript渲染的工具，本节来介绍它的安装方式  要装docker|\n",
    "|| Scrapy-Redis✅ | 方便地实现 Scrapy分布式爬虫的搭建 |\n",
    "| 部署相关库 | Docker✅ | Docker 是一种容器技术，可以将应用和环境等进行打包，形成一个独立的、类似于 iOS 的 App 形式的“应用”。 这个应用可以直接被分发到任意一个支持 Docker的环境中， 通过简单的命令即可启 动运行。 |\n",
    "|| Scrapyd | 一个用于部署和l运行 Scrapy项目的工具， 有了它，你可以将写好的 Scrapy项目上传到 云主机并通过 API来控制它的运行。crapy项目部署，基本上都使用 Linux主机，所以本节的安装是针对于 **Linux主机**的 |\n",
    "|| Scrapyd-Client | 在将 Scrapy代码部署到远程 Scrapyd 的时候，第一步就是要将代码打包为 EGG 文件，其次需要 将 EGG 文件上传到远程主机。 这个过程如果用程序来实现，也是完全可以的，但是我们并不需要做 这些t作，因为 Scrapyd-Client已经为我们实现了这些功能。 |\n",
    "|| Scrapyd API | 安装好了 Scrapyd之后，我们可以直接请求它提供的 API来获取当前主机的 Scrapy任务运行状况 |\n",
    "|| Scrapyrt | Scrapyrt为 Scrapy提供了一个调度的 HTTP接口，有了它，我们就不需要再执行 Scrapy命令而是 通过请求一个 HTTP 接口来调度 Scrapy任务了 。 Scrapyrt 比 Scrapyd更轻量，如果不需要分布式多任 务的话 ，可以简单使用 Scrapyrt实现远程 Scrapy任务的调度 。 |\n",
    "|| Gerapy | Gerapy是一个 Scrapy分布式管理模块 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在安装 tesserocr 的时候出现了问题，报错放在install_error1中，不过好在已经解决了，将报错文件的中的 <cstdint> 改成 <tr1/stdint>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
